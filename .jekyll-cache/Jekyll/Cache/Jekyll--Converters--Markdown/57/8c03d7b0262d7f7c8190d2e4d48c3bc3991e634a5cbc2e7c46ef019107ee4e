I"Î<h2 id="terms">Terms:</h2>
<ul>
  <li>Active inference</li>
  <li><a href="https://en.wikipedia.org/wiki/Predictive_coding">Predictive Processing/Predictive Coding</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Free_energy_principle">Free Energy Principle</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Markov_blanket">Markov Blanket</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Theory_of_reasoned_action">Model of Action</a></li>
</ul>

<h2 id="classical-model-of-action">Classical model of action:</h2>
<ul>
  <li>Optimal action depends on state of the world</li>
  <li>Therefore, first step of action is to (1) form a belief (analyse surroundings/prospects)</li>
  <li>(2) imagine a value function of next state brought about by action</li>
  <li>(3) optimise action that maximises value of the next state</li>
</ul>

<h2 id="model-of-action">Model of action</h2>
<ul>
  <li>Classical model doesnâ€™t work when the best next thing to do is to search for/resolve uncertainty</li>
  <li>Optimal action depends on beliefs about the world, and subsequent action</li>
  <li>Further, itâ€™s a function of the order in which you interrogate the world</li>
  <li>Therefore the functional (function of a function) to be optimised is a function of beliefs</li>
  <li>Optimal action therefore is optimising sequences or policies of actions</li>
  <li>To be optimised: a function of a belief, integrated over time</li>
</ul>

<h2 id="free-energy-principle">Free Energy Principle:</h2>

<ul>
  <li>The goal of a self-organising (eg biological) system is to minimise prediction error (surprise), also called â€˜free energyâ€™, by forming continually-updated beliefs/inferences about the world from which to form policies of action</li>
  <li>Friston considers this an organising principle of all life and intelligence</li>
  <li>
    <p>To be alive (to be a system that resists disorder and dissolution) is to act in ways that reduce the gulf between your expectations and your sensory inputs (AKA, to minimise free energy)</p>
  </li>
  <li>If a prototypical agent, or a â€˜good agentâ€™ minimises free energy (thereby minimising â€˜surpriseâ€™), they must believe that the actions they take minimised expected free energy</li>
  <li>expected free energy associated with a policy of action is minimised</li>
</ul>

<h2 id="markov-blanket">Markov Blanket:</h2>
<p>The Markov Blanket is a concept in machine learning which is essentially a shield that separates one set of variables from others in a layered, hierarchical system. The blanket defines the boundaries of a given system. That is, in cognition, a cognitive version of a cell membrane shielding states inside the blanket from states outside. This is the schema by which surprise is minimisedâ€” the Markov blanket is a set of variables sufficiently complete that another random variable can be inferred from it . If a Markov blanket is minimal (parsimonious) (cannot drop any variable without losing information), it is called a Markov boundary.</p>
:ET